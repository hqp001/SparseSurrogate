{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769991e-deb9-4466-a68d-8394690cf905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.6549\n",
      "Epoch [2/20], Training Loss: 1.1342\n",
      "Epoch [3/20], Training Loss: 0.7331\n",
      "Epoch [4/20], Training Loss: 0.7146\n",
      "Epoch [5/20], Training Loss: 0.7270\n",
      "Epoch [6/20], Training Loss: 0.8236\n",
      "Epoch [7/20], Training Loss: 0.7222\n",
      "Epoch [8/20], Training Loss: 1.5268\n",
      "Epoch [9/20], Training Loss: 0.7172\n",
      "Epoch [10/20], Training Loss: 0.7920\n",
      "Epoch [11/20], Training Loss: 0.6583\n",
      "Epoch [12/20], Training Loss: 0.6599\n",
      "Epoch [13/20], Training Loss: 0.7372\n",
      "Epoch [14/20], Training Loss: 0.7183\n",
      "Epoch [15/20], Training Loss: 0.6466\n",
      "Epoch [16/20], Training Loss: 0.6523\n",
      "Epoch [17/20], Training Loss: 0.8862\n",
      "Epoch [18/20], Training Loss: 0.6627\n",
      "Epoch [19/20], Training Loss: 0.7616\n",
      "Epoch [20/20], Training Loss: 0.7739\n",
      "After fine-tuning round 1, non-zero parameters: 1696\n",
      "After pruning round 1, non-zero parameters: 1444\n",
      "After fine-tuning round 2, non-zero parameters: 1444\n",
      "After pruning round 2, non-zero parameters: 1229\n",
      "After fine-tuning round 3, non-zero parameters: 1229\n",
      "After pruning round 3, non-zero parameters: 1046\n",
      "After fine-tuning round 4, non-zero parameters: 1046\n",
      "After pruning round 4, non-zero parameters: 891\n",
      "After fine-tuning round 5, non-zero parameters: 891\n",
      "After pruning round 5, non-zero parameters: 759\n",
      "After fine-tuning round 6, non-zero parameters: 759\n",
      "After pruning round 6, non-zero parameters: 646\n",
      "After fine-tuning round 7, non-zero parameters: 646\n",
      "After pruning round 7, non-zero parameters: 550\n",
      "After fine-tuning round 8, non-zero parameters: 550\n",
      "After pruning round 8, non-zero parameters: 468\n",
      "After fine-tuning round 9, non-zero parameters: 468\n",
      "After pruning round 9, non-zero parameters: 398\n",
      "After fine-tuning round 10, non-zero parameters: 398\n",
      "After pruning round 10, non-zero parameters: 339\n",
      "Final non-zero parameters: 339\n",
      "Epoch [1/20], Training Loss: 0.6549\n",
      "Epoch [2/20], Training Loss: 1.1342\n",
      "Epoch [3/20], Training Loss: 0.7331\n",
      "Epoch [4/20], Training Loss: 0.7146\n",
      "Epoch [5/20], Training Loss: 0.7270\n",
      "Epoch [6/20], Training Loss: 0.8236\n",
      "Epoch [7/20], Training Loss: 0.7222\n",
      "Epoch [8/20], Training Loss: 1.5268\n",
      "Epoch [9/20], Training Loss: 0.7172\n",
      "Epoch [10/20], Training Loss: 0.7920\n",
      "Epoch [11/20], Training Loss: 0.6583\n",
      "Epoch [12/20], Training Loss: 0.6599\n",
      "Epoch [13/20], Training Loss: 0.7372\n",
      "Epoch [14/20], Training Loss: 0.7183\n",
      "Epoch [15/20], Training Loss: 0.6466\n",
      "Epoch [16/20], Training Loss: 0.6523\n",
      "Epoch [17/20], Training Loss: 0.8862\n",
      "Epoch [18/20], Training Loss: 0.6627\n",
      "Epoch [19/20], Training Loss: 0.7616\n",
      "Epoch [20/20], Training Loss: 0.7739\n",
      "wrote problem to file C:\\Users\\20239\\Desktop\\my files\\2024 Summer NSF\\MLResearch2024_2ndPhase\\Water\\code\\water_20_mlp-bigm_7_16_torch_0_0_sparsity_80.mps\n",
      "Epoch [1/20], Training Loss: 0.6549\n",
      "Epoch [2/20], Training Loss: 1.1342\n",
      "Epoch [3/20], Training Loss: 0.7331\n",
      "Epoch [4/20], Training Loss: 0.7146\n",
      "Epoch [5/20], Training Loss: 0.7270\n",
      "Epoch [6/20], Training Loss: 0.8236\n",
      "Epoch [7/20], Training Loss: 0.7222\n",
      "Epoch [8/20], Training Loss: 1.5268\n",
      "Epoch [9/20], Training Loss: 0.7172\n",
      "Epoch [10/20], Training Loss: 0.7920\n",
      "Epoch [11/20], Training Loss: 0.6583\n",
      "Epoch [12/20], Training Loss: 0.6599\n",
      "Epoch [13/20], Training Loss: 0.7372\n",
      "Epoch [14/20], Training Loss: 0.7183\n",
      "Epoch [15/20], Training Loss: 0.6466\n",
      "Epoch [16/20], Training Loss: 0.6523\n",
      "Epoch [17/20], Training Loss: 0.8862\n",
      "Epoch [18/20], Training Loss: 0.6627\n",
      "Epoch [19/20], Training Loss: 0.7616\n",
      "Epoch [20/20], Training Loss: 0.7739\n",
      "After fine-tuning round 1, non-zero parameters: 1696\n",
      "After pruning round 1, non-zero parameters: 1444\n",
      "After fine-tuning round 2, non-zero parameters: 1444\n",
      "After pruning round 2, non-zero parameters: 1229\n",
      "After fine-tuning round 3, non-zero parameters: 1229\n",
      "After pruning round 3, non-zero parameters: 1046\n",
      "After fine-tuning round 4, non-zero parameters: 1046\n",
      "After pruning round 4, non-zero parameters: 891\n",
      "After fine-tuning round 5, non-zero parameters: 891\n",
      "After pruning round 5, non-zero parameters: 759\n",
      "After fine-tuning round 6, non-zero parameters: 759\n",
      "After pruning round 6, non-zero parameters: 646\n",
      "After fine-tuning round 7, non-zero parameters: 646\n",
      "After pruning round 7, non-zero parameters: 550\n",
      "After fine-tuning round 8, non-zero parameters: 550\n",
      "After pruning round 8, non-zero parameters: 468\n",
      "After fine-tuning round 9, non-zero parameters: 468\n",
      "After pruning round 9, non-zero parameters: 398\n",
      "After fine-tuning round 10, non-zero parameters: 398\n",
      "After pruning round 10, non-zero parameters: 339\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "# Define parameters\n",
    "write_only = True\n",
    "time_limit = 1200\n",
    "generate_water = True  # Set to True to generate ensemble water instances\n",
    "\n",
    "use_pruned_model = True  # Set to True to use the pruned model\n",
    "total_sparsity = 0.8  # Set the desired total sparsity level for pruning\n",
    "\n",
    "# Choose the correct module and function based on the `use_pruned_model` flag\n",
    "if use_pruned_model:\n",
    "    module_name = \"pruned_test_water_potability\"\n",
    "else:\n",
    "    module_name = \"test_water_potability\"\n",
    "\n",
    "# Dynamically import the chosen module\n",
    "module = importlib.import_module(module_name)\n",
    "\n",
    "# Loop through seeds and generate instances\n",
    "for d_s in [0, 1]:\n",
    "    for t_s in [0, 1]:\n",
    "        # Generate the water instances\n",
    "        water_data = []\n",
    "        for n_w in [20]:\n",
    "            # Generate the neural network instances\n",
    "            for formulation in [\"bigm\", \"sos\"]:\n",
    "                for n_e, d in [(7, 16)]:\n",
    "                    if generate_water:\n",
    "                        if use_pruned_model:\n",
    "                            scip = module.build_and_optimise_water_potability(\n",
    "                                data_seed=d_s,\n",
    "                                training_seed=t_s,\n",
    "                                predictor_type=\"mlp\",\n",
    "                                formulation=formulation,\n",
    "                                n_water_samples=n_w,\n",
    "                                layer_size=d,\n",
    "                                n_estimators_layers=n_e,\n",
    "                                framework=\"torch\",\n",
    "                                build_only=True,\n",
    "                                total_sparsity=total_sparsity,  # Pass sparsity to the pruned model\n",
    "                            )\n",
    "                            filename = f\"water_{n_w}_mlp-{formulation}_{n_e}_{d}_torch_{d_s}_{t_s}_sparsity_{int(total_sparsity*100)}.mps\"\n",
    "                        else:\n",
    "                            scip = module.build_and_optimise_water_potability(\n",
    "                                data_seed=d_s,\n",
    "                                training_seed=t_s,\n",
    "                                predictor_type=\"mlp\",\n",
    "                                formulation=formulation,\n",
    "                                n_water_samples=n_w,\n",
    "                                layer_size=d,\n",
    "                                n_estimators_layers=n_e,\n",
    "                                framework=\"torch\",\n",
    "                                build_only=True,\n",
    "                            )\n",
    "                            filename = f\"water_{n_w}_mlp-{formulation}_{n_e}_{d}_torch_{d_s}_{t_s}.mps\"\n",
    "\n",
    "                        if write_only:\n",
    "                            scip.writeProblem(filename)\n",
    "                        else:\n",
    "                            scip.setParam(\"limits/time\", time_limit)\n",
    "                            scip.optimize()\n",
    "                            water_data.append(\n",
    "                                [\n",
    "                                    n_w,\n",
    "                                    \"mlp\",\n",
    "                                    \"torch\",\n",
    "                                    n_e,\n",
    "                                    d,\n",
    "                                    scip.getStatus(),\n",
    "                                    scip.getSolvingTime(),\n",
    "                                    scip.getNTotalNodes(),\n",
    "                                ]\n",
    "                            )\n",
    "\n",
    "if not write_only:\n",
    "    if generate_water:\n",
    "        print(f\"water: {water_data}\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05424618-a69e-465d-aa31-80b56dd862fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
